#agent
customInterceptor.sources=r1
customInterceptor.channels=c1
customInterceptor.sinks=s1

#source
#customInterceptor.sources.r1.type=exec
#customInterceptor.sources.r1.command=tail -f /opt/module/logs/log/postgresql-2019-03-20_092822.log
customInterceptor.sources.r1.type = TAILDIR
customInterceptor.sources.r1.positionFile = /opt/module/logs/taildir_position.json
customInterceptor.sources.r1.filegroups=f1
customInterceptor.sources.r1.filegroups.f1= /opt/module/logs/log/postgresql-2019-03-20_092822.log
customInterceptor.sources.r1.fileHeader=true
#source1-interceptor
customInterceptor.sources.r1.interceptors=i1
customInterceptor.sources.r1.interceptors.i1.type=cn.com.lgh.interceptor.CustomInterceptor$Builder
customInterceptor.sources.r1.interceptors.i1.format=%m&0-2 %c&3 %d&4 %p&5 %a&6 %x&7 %n&8 %e&9
customInterceptor.sources.r1.interceptors.i1.param=HWMPPD

#channe1
customInterceptor.channels.c1.type=memory
customInterceptor.channels.c1.capacity=1000
customInterceptor.channels.c1.transactionCapacity=100

#sink
#设置Kafka接收器
customInterceptor.sinks.s1.type= org.apache.flume.sink.kafka.KafkaSink
#设置Kafka的broker地址和端口号
customInterceptor.sinks.s1.brokerList=192.168.0.20:9092
#设置Kafka的Topic
customInterceptor.sinks.s1.topic=first
#设置序列化方式
customInterceptor.sinks.s1.serializer.class=kafka.serializer.StringEncoder

#package
customInterceptor.sources.r1.channels=c1
customInterceptor.sinks.s1.channel=c1



